{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charity  Data\n",
    "\n",
    "\n",
    "## using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T21:42:40.402601Z",
     "start_time": "2020-02-06T21:42:40.396481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 0.21.3\n"
     ]
    }
   ],
   "source": [
    "# import libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "# check scikit-learn version\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T21:42:40.417625Z",
     "start_time": "2020-02-06T21:42:40.404744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45217</td>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45218</td>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45219</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45220</td>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45221</td>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass education_level  education-num  \\\n",
       "0       39          State-gov       Bachelors           13.0   \n",
       "1       50   Self-emp-not-inc       Bachelors           13.0   \n",
       "2       38            Private         HS-grad            9.0   \n",
       "3       53            Private            11th            7.0   \n",
       "4       28            Private       Bachelors           13.0   \n",
       "...    ...                ...             ...            ...   \n",
       "45217   33            Private       Bachelors           13.0   \n",
       "45218   39            Private       Bachelors           13.0   \n",
       "45219   38            Private       Bachelors           13.0   \n",
       "45220   44            Private       Bachelors           13.0   \n",
       "45221   35       Self-emp-inc       Bachelors           13.0   \n",
       "\n",
       "            marital-status          occupation    relationship  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   \n",
       "...                    ...                 ...             ...   \n",
       "45217        Never-married      Prof-specialty       Own-child   \n",
       "45218             Divorced      Prof-specialty   Not-in-family   \n",
       "45219   Married-civ-spouse      Prof-specialty         Husband   \n",
       "45220             Divorced        Adm-clerical       Own-child   \n",
       "45221   Married-civ-spouse     Exec-managerial         Husband   \n",
       "\n",
       "                      race      sex  capital-gain  capital-loss  \\\n",
       "0                    White     Male        2174.0           0.0   \n",
       "1                    White     Male           0.0           0.0   \n",
       "2                    White     Male           0.0           0.0   \n",
       "3                    Black     Male           0.0           0.0   \n",
       "4                    Black   Female           0.0           0.0   \n",
       "...                    ...      ...           ...           ...   \n",
       "45217                White     Male           0.0           0.0   \n",
       "45218                White   Female           0.0           0.0   \n",
       "45219                White     Male           0.0           0.0   \n",
       "45220   Asian-Pac-Islander     Male        5455.0           0.0   \n",
       "45221                White     Male           0.0           0.0   \n",
       "\n",
       "       hours-per-week  native-country income  \n",
       "0                40.0   United-States  <=50K  \n",
       "1                13.0   United-States  <=50K  \n",
       "2                40.0   United-States  <=50K  \n",
       "3                40.0   United-States  <=50K  \n",
       "4                40.0            Cuba  <=50K  \n",
       "...               ...             ...    ...  \n",
       "45217            40.0   United-States  <=50K  \n",
       "45218            36.0   United-States  <=50K  \n",
       "45219            50.0   United-States  <=50K  \n",
       "45220            40.0   United-States  <=50K  \n",
       "45221            60.0   United-States   >50K  \n",
       "\n",
       "[45222 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/mnt/1A746F7B746F5891/L U N I X/Machine learning/datasets/udacity-mlcharity-competition/census.csv')\n",
    "# #drop rows to be string number\n",
    "# dataset=dataset_not_adjust.drop(dataset.index[[-1,-2]])\n",
    "# dataset\n",
    "features = dataset.iloc[:,:-1].values\n",
    "goal = dataset.iloc[:,-1].values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                     age  education-num  capital-gain  capital-loss  \\\n",
       " age             1.000000       0.037623      0.079683      0.059351   \n",
       " education-num   0.037623       1.000000      0.126907      0.081711   \n",
       " capital-gain    0.079683       0.126907      1.000000     -0.032102   \n",
       " capital-loss    0.059351       0.081711     -0.032102      1.000000   \n",
       " hours-per-week  0.101992       0.146206      0.083880      0.054195   \n",
       " \n",
       "                 hours-per-week  \n",
       " age                   0.101992  \n",
       " education-num         0.146206  \n",
       " capital-gain          0.083880  \n",
       " capital-loss          0.054195  \n",
       " hours-per-week        1.000000  ,\n",
       "                         age  education-num  capital-gain   capital-loss  \\\n",
       " age              174.712093       1.269536  7.906093e+03     317.683292   \n",
       " education-num      1.269536       6.517202  2.431918e+03      84.473549   \n",
       " capital-gain    7906.092955    2431.918128  5.634649e+07  -97583.839752   \n",
       " capital-loss     317.683292      84.473549 -9.758384e+04  163989.436496   \n",
       " hours-per-week    16.187565       4.481768  7.560437e+03     263.523274   \n",
       " \n",
       "                 hours-per-week  \n",
       " age                  16.187565  \n",
       " education-num         4.481768  \n",
       " capital-gain       7560.437457  \n",
       " capital-loss        263.523274  \n",
       " hours-per-week      144.180254  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#whate is the Correlation and Covarians???\n",
    "dataset.corr(),dataset.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "workclass          0\n",
       "education_level    0\n",
       "education-num      0\n",
       "marital-status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "sex                0\n",
       "capital-gain       0\n",
       "capital-loss       0\n",
       "hours-per-week     0\n",
       "native-country     0\n",
       "income             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there any data NAN\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(age                  int64\n",
       " workclass           object\n",
       " education_level     object\n",
       " education-num      float64\n",
       " marital-status      object\n",
       " occupation          object\n",
       " relationship        object\n",
       " race                object\n",
       " sex                 object\n",
       " capital-gain       float64\n",
       " capital-loss       float64\n",
       " hours-per-week     float64\n",
       " native-country      object\n",
       " income              object\n",
       " dtype: object,\n",
       "                 age  education-num  capital-gain  capital-loss  hours-per-week\n",
       " count  45222.000000   45222.000000  45222.000000  45222.000000    45222.000000\n",
       " mean      38.547941      10.118460   1101.430344     88.595418       40.938017\n",
       " std       13.217870       2.552881   7506.430084    404.956092       12.007508\n",
       " min       17.000000       1.000000      0.000000      0.000000        1.000000\n",
       " 25%       28.000000       9.000000      0.000000      0.000000       40.000000\n",
       " 50%       37.000000      10.000000      0.000000      0.000000       40.000000\n",
       " 75%       47.000000      13.000000      0.000000      0.000000       45.000000\n",
       " max       90.000000      16.000000  99999.000000   4356.000000       99.000000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the type of feauters\n",
    "dataset.dtypes,dataset.describe()# we found out 9 bojects need tor encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handel Categorical DAta\n",
    "# # Methods  of encoding:\n",
    "\n",
    "we can use select_dtypes and build new df contain only the objects columns\n",
    "    obj_df=df.select_dtypes(include=[\"object\"]).copy()\n",
    "\n",
    "Approach #1 Find and Replace: \n",
    "                            new_dic={\"featur1\":{\"cat1':1,\"cat2:2},\"featur2:{}.....}\n",
    "                            dataset.replace(new_dic,inplace=True)\n",
    "\n",
    "Approach #2 Label Encoding   1-change type of data to category.....dataset[\"feature\"]=dataset[\"feature\"].astype(\"category\")\n",
    "2- creat new column and assign variable to new column using.codes\n",
    "dataset[\"feature_new\"]=dataset[\"feature\"].cat.codes\n",
    "\n",
    "3- One Hot Encoding\n",
    "pd.get_dummies(obj_df,col.umns=[\"feature1\",\"feature2\"],prefix=[\"f1\",\"f2\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.get_dummies(dataset,columns=[\"workclass\",\"education_level\"],prefix=[\"w1\",\"ed_l\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data to dependand and independant X , Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split your dependant and independant variables\n",
    "training_data = dataset.iloc[:, :-1]\n",
    "goal_data = dataset.iloc[:, -1]# using .values make it array not dataframe\n",
    "\n",
    "befor_encoding=pd.DataFrame(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply encoding to Features\n",
    "\n",
    "Implement LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder ,OneHotEncoder\n",
    "features_objects=[\"workclass\",\"education_level\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native-country\"]\n",
    "features_indeces=[1,2,4,5,6,7,8,12]\n",
    "\n",
    "#apply labelEncoder\n",
    "for i,j in zip(features_objects,features_indeces):\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(training_data[i]);\n",
    "    training_data[i]=label_encoder.transform(training_data[i]);\n",
    "\n",
    "# #label encode for all dataset to calculate the correlation and describion of dataset and get the more importand features\n",
    "#     label_encoder.fit(dataset[i]);\n",
    "#     dataset[i]=label_encoder.transform(dataset[i]);\n",
    "\n",
    "after_label=pd.DataFrame(training_data)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/1A746F7B746F5891/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/mnt/1A746F7B746F5891/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/mnt/1A746F7B746F5891/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/mnt/1A746F7B746F5891/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/mnt/1A746F7B746F5891/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/mnt/1A746F7B746F5891/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/mnt/1A746F7B746F5891/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/mnt/1A746F7B746F5891/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "befor_encoding:\n",
      "\n",
      "        age  workclass  education_level  education-num  marital-status  \\\n",
      "0       39          5                9           13.0               4   \n",
      "1       50          4                9           13.0               2   \n",
      "2       38          2               11            9.0               0   \n",
      "3       53          2                1            7.0               2   \n",
      "4       28          2                9           13.0               2   \n",
      "...    ...        ...              ...            ...             ...   \n",
      "45217   33          2                9           13.0               4   \n",
      "45218   39          2                9           13.0               0   \n",
      "45219   38          2                9           13.0               2   \n",
      "45220   44          2                9           13.0               0   \n",
      "45221   35          3                9           13.0               2   \n",
      "\n",
      "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
      "0               0             1     4    1        2174.0           0.0   \n",
      "1               3             0     4    1           0.0           0.0   \n",
      "2               5             1     4    1           0.0           0.0   \n",
      "3               5             0     2    1           0.0           0.0   \n",
      "4               9             5     2    0           0.0           0.0   \n",
      "...           ...           ...   ...  ...           ...           ...   \n",
      "45217           9             3     4    1           0.0           0.0   \n",
      "45218           9             1     4    0           0.0           0.0   \n",
      "45219           9             0     4    1           0.0           0.0   \n",
      "45220           0             3     1    1        5455.0           0.0   \n",
      "45221           3             0     4    1           0.0           0.0   \n",
      "\n",
      "       hours-per-week  native-country  \n",
      "0                40.0              38  \n",
      "1                13.0              38  \n",
      "2                40.0              38  \n",
      "3                40.0              38  \n",
      "4                40.0               4  \n",
      "...               ...             ...  \n",
      "45217            40.0              38  \n",
      "45218            36.0              38  \n",
      "45219            50.0              38  \n",
      "45220            40.0              38  \n",
      "45221            60.0              38  \n",
      "\n",
      "[45222 rows x 13 columns]\n",
      "after_label :\n",
      "\n",
      "       age  workclass  education_level  education-num  marital-status  \\\n",
      "0       39          5                9           13.0               4   \n",
      "1       50          4                9           13.0               2   \n",
      "2       38          2               11            9.0               0   \n",
      "3       53          2                1            7.0               2   \n",
      "4       28          2                9           13.0               2   \n",
      "...    ...        ...              ...            ...             ...   \n",
      "45217   33          2                9           13.0               4   \n",
      "45218   39          2                9           13.0               0   \n",
      "45219   38          2                9           13.0               2   \n",
      "45220   44          2                9           13.0               0   \n",
      "45221   35          3                9           13.0               2   \n",
      "\n",
      "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
      "0               0             1     4    1        2174.0           0.0   \n",
      "1               3             0     4    1           0.0           0.0   \n",
      "2               5             1     4    1           0.0           0.0   \n",
      "3               5             0     2    1           0.0           0.0   \n",
      "4               9             5     2    0           0.0           0.0   \n",
      "...           ...           ...   ...  ...           ...           ...   \n",
      "45217           9             3     4    1           0.0           0.0   \n",
      "45218           9             1     4    0           0.0           0.0   \n",
      "45219           9             0     4    1           0.0           0.0   \n",
      "45220           0             3     1    1        5455.0           0.0   \n",
      "45221           3             0     4    1           0.0           0.0   \n",
      "\n",
      "       hours-per-week  native-country  \n",
      "0                40.0              38  \n",
      "1                13.0              38  \n",
      "2                40.0              38  \n",
      "3                40.0              38  \n",
      "4                40.0               4  \n",
      "...               ...             ...  \n",
      "45217            40.0              38  \n",
      "45218            36.0              38  \n",
      "45219            50.0              38  \n",
      "45220            40.0              38  \n",
      "45221            60.0              38  \n",
      "\n",
      "[45222 rows x 13 columns]\n",
      "after_OnehotEnder:\n",
      "\n",
      "         0    1    2    3    4    5    6    7    8    9   ...    16   17   18  \\\n",
      "0      1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  13.0  4.0  0.0   \n",
      "1      1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  13.0  2.0  3.0   \n",
      "2      1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...   9.0  0.0  5.0   \n",
      "3      1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...   7.0  2.0  5.0   \n",
      "4      1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  13.0  2.0  9.0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...  ...   \n",
      "45217  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  13.0  4.0  9.0   \n",
      "45218  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  13.0  0.0  9.0   \n",
      "45219  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  13.0  2.0  9.0   \n",
      "45220  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  13.0  0.0  0.0   \n",
      "45221  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  13.0  2.0  3.0   \n",
      "\n",
      "        19   20   21      22   23    24    25  \n",
      "0      1.0  4.0  1.0  2174.0  0.0  40.0  38.0  \n",
      "1      0.0  4.0  1.0     0.0  0.0  13.0  38.0  \n",
      "2      1.0  4.0  1.0     0.0  0.0  40.0  38.0  \n",
      "3      0.0  2.0  1.0     0.0  0.0  40.0  38.0  \n",
      "4      5.0  2.0  0.0     0.0  0.0  40.0   4.0  \n",
      "...    ...  ...  ...     ...  ...   ...   ...  \n",
      "45217  3.0  4.0  1.0     0.0  0.0  40.0  38.0  \n",
      "45218  1.0  4.0  0.0     0.0  0.0  36.0  38.0  \n",
      "45219  0.0  4.0  1.0     0.0  0.0  50.0  38.0  \n",
      "45220  3.0  1.0  1.0  5455.0  0.0  40.0  38.0  \n",
      "45221  0.0  4.0  1.0     0.0  0.0  60.0  38.0  \n",
      "\n",
      "[45222 rows x 26 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9   ...    16   17   18  \\\n",
       "0      1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  13.0  4.0  0.0   \n",
       "1      1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  13.0  2.0  3.0   \n",
       "2      1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...   9.0  0.0  5.0   \n",
       "3      1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...   7.0  2.0  5.0   \n",
       "4      1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  13.0  2.0  9.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...  ...   \n",
       "45217  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  13.0  4.0  9.0   \n",
       "45218  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  13.0  0.0  9.0   \n",
       "45219  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  13.0  2.0  9.0   \n",
       "45220  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  13.0  0.0  0.0   \n",
       "45221  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  13.0  2.0  3.0   \n",
       "\n",
       "        19   20   21      22   23    24    25  \n",
       "0      1.0  4.0  1.0  2174.0  0.0  40.0  38.0  \n",
       "1      0.0  4.0  1.0     0.0  0.0  13.0  38.0  \n",
       "2      1.0  4.0  1.0     0.0  0.0  40.0  38.0  \n",
       "3      0.0  2.0  1.0     0.0  0.0  40.0  38.0  \n",
       "4      5.0  2.0  0.0     0.0  0.0  40.0   4.0  \n",
       "...    ...  ...  ...     ...  ...   ...   ...  \n",
       "45217  3.0  4.0  1.0     0.0  0.0  40.0  38.0  \n",
       "45218  1.0  4.0  0.0     0.0  0.0  36.0  38.0  \n",
       "45219  0.0  4.0  1.0     0.0  0.0  50.0  38.0  \n",
       "45220  3.0  1.0  1.0  5455.0  0.0  40.0  38.0  \n",
       "45221  0.0  4.0  1.0     0.0  0.0  60.0  38.0  \n",
       "\n",
       "[45222 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply onehotencoder\n",
    "for i,j in zip(features_objects,features_indeces):\n",
    "\n",
    "    oneHotEncoder = OneHotEncoder(categorical_features=[j]);\n",
    "    training_data = oneHotEncoder.fit_transform(training_data).toarray();\n",
    "\n",
    "after_OneHotEncoder=pd.DataFrame(training_data)\n",
    "\n",
    "print(\"befor_encoding:\\n\\n {}\\nafter_label :\\n\\n{}\\nafter_OnehotEnder:\\n\\n {}\".format(befor_encoding,after_label,after_OneHotEncoder))\n",
    "\n",
    "#Encoding Y\n",
    "goal_train = label_encoder.fit_transform(goal_data)\n",
    "pd.DataFrame(training_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_objects=[\"workclass\",\"education_level\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native-country\",\"income\"]\n",
    "features_indeces=[1,2,4,5,6,7,8,12,13]\n",
    "\n",
    "# fig,axs=plt.subplots(1,2,3,4)\n",
    "for i in features_objects:\n",
    "    dataset[i].value_counts().plot.bar()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the needed librarys to encode the target or Y or goal_train\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "goal_data = encoder.fit_transform(goal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standrize the values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "training_data = scaler.fit_transform(training_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split X & Y to Train and Test 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "      <td>36177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>-0.002309</td>\n",
       "      <td>-0.003147</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>-0.003147</td>\n",
       "      <td>-0.005290</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>-0.004169</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.944956</td>\n",
       "      <td>0.944956</td>\n",
       "      <td>1.001697</td>\n",
       "      <td>1.001697</td>\n",
       "      <td>1.001697</td>\n",
       "      <td>1.001697</td>\n",
       "      <td>1.014192</td>\n",
       "      <td>1.014192</td>\n",
       "      <td>1.001887</td>\n",
       "      <td>1.001887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999261</td>\n",
       "      <td>1.000483</td>\n",
       "      <td>0.999651</td>\n",
       "      <td>1.000213</td>\n",
       "      <td>0.996383</td>\n",
       "      <td>1.000084</td>\n",
       "      <td>1.019516</td>\n",
       "      <td>0.999196</td>\n",
       "      <td>0.993274</td>\n",
       "      <td>0.996228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-46.394273</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>-5.582435</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>-3.686155</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.571870</td>\n",
       "      <td>-1.722946</td>\n",
       "      <td>-1.482624</td>\n",
       "      <td>-0.884479</td>\n",
       "      <td>-4.421598</td>\n",
       "      <td>-1.441310</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>-3.326124</td>\n",
       "      <td>-5.987218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-0.390005</td>\n",
       "      <td>-0.985897</td>\n",
       "      <td>-0.884479</td>\n",
       "      <td>0.384110</td>\n",
       "      <td>-1.441310</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046403</td>\n",
       "      <td>-0.390005</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>-0.258387</td>\n",
       "      <td>0.384110</td>\n",
       "      <td>0.693813</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>1.671940</td>\n",
       "      <td>1.671940</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128753</td>\n",
       "      <td>0.942936</td>\n",
       "      <td>0.752648</td>\n",
       "      <td>0.993798</td>\n",
       "      <td>0.384110</td>\n",
       "      <td>0.693813</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>0.338291</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>46.394273</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>1.671940</td>\n",
       "      <td>1.671940</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>5.582435</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>3.686155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.303909</td>\n",
       "      <td>2.275877</td>\n",
       "      <td>1.746102</td>\n",
       "      <td>2.245982</td>\n",
       "      <td>0.384110</td>\n",
       "      <td>0.693813</td>\n",
       "      <td>13.175193</td>\n",
       "      <td>10.538060</td>\n",
       "      <td>4.835527</td>\n",
       "      <td>0.591958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  36177.000000  36177.000000  36177.000000  36177.000000  36177.000000   \n",
       "mean       0.002309     -0.002309     -0.003147      0.003147      0.003147   \n",
       "std        0.944956      0.944956      1.001697      1.001697      1.001697   \n",
       "min      -46.394273     -0.021554     -1.671940     -0.598108     -0.598108   \n",
       "25%        0.021554     -0.021554     -1.671940     -0.598108     -0.598108   \n",
       "50%        0.021554     -0.021554      0.598108     -0.598108     -0.598108   \n",
       "75%        0.021554     -0.021554      0.598108      1.671940      1.671940   \n",
       "max        0.021554     46.394273      0.598108      1.671940      1.671940   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  36177.000000  36177.000000  36177.000000  36177.000000  36177.000000   \n",
       "mean      -0.003147     -0.005290      0.005290     -0.001098      0.001098   \n",
       "std        1.001697      1.014192      1.014192      1.001887      1.001887   \n",
       "min       -1.671940     -5.582435     -0.179133     -3.686155     -0.271285   \n",
       "25%       -1.671940      0.179133     -0.179133      0.271285     -0.271285   \n",
       "50%        0.598108      0.179133     -0.179133      0.271285     -0.271285   \n",
       "75%        0.598108      0.179133     -0.179133      0.271285     -0.271285   \n",
       "max        0.598108      0.179133      5.582435      0.271285      3.686155   \n",
       "\n",
       "       ...            16            17            18            19  \\\n",
       "count  ...  36177.000000  36177.000000  36177.000000  36177.000000   \n",
       "mean   ...     -0.000666      0.001197     -0.004169     -0.000920   \n",
       "std    ...      0.999261      1.000483      0.999651      1.000213   \n",
       "min    ...     -3.571870     -1.722946     -1.482624     -0.884479   \n",
       "25%    ...     -0.438122     -0.390005     -0.985897     -0.884479   \n",
       "50%    ...     -0.046403     -0.390005      0.007557     -0.258387   \n",
       "75%    ...      1.128753      0.942936      0.752648      0.993798   \n",
       "max    ...      2.303909      2.275877      1.746102      2.245982   \n",
       "\n",
       "                 20            21            22            23            24  \\\n",
       "count  36177.000000  36177.000000  36177.000000  36177.000000  36177.000000   \n",
       "mean       0.001169     -0.000189      0.003427     -0.000068      0.000441   \n",
       "std        0.996383      1.000084      1.019516      0.999196      0.993274   \n",
       "min       -4.421598     -1.441310     -0.146733     -0.218780     -3.326124   \n",
       "25%        0.384110     -1.441310     -0.146733     -0.218780     -0.078120   \n",
       "50%        0.384110      0.693813     -0.146733     -0.218780     -0.078120   \n",
       "75%        0.384110      0.693813     -0.146733     -0.218780      0.338291   \n",
       "max        0.384110      0.693813     13.175193     10.538060      4.835527   \n",
       "\n",
       "                 25  \n",
       "count  36177.000000  \n",
       "mean       0.001833  \n",
       "std        0.996228  \n",
       "min       -5.987218  \n",
       "25%        0.262999  \n",
       "50%        0.262999  \n",
       "75%        0.262999  \n",
       "max        0.591958  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set, goal_train, goal_test = train_test_split(training_data,goal_data,test_size =0.2,random_state=0)\n",
    "df=pd.DataFrame(train_set)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the best features from dataset using chi2\n",
    ".....features must be non-negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        21\n",
       "1     45201\n",
       "2     11915\n",
       "3     33307\n",
       "4     33307\n",
       "5     11915\n",
       "6      1406\n",
       "7     43816\n",
       "8      3100\n",
       "9     42122\n",
       "10     1646\n",
       "11    43576\n",
       "12    41426\n",
       "13    43276\n",
       "14    24238\n",
       "15    17169\n",
       "16    30343\n",
       "17    27384\n",
       "18    21084\n",
       "19    30368\n",
       "20     6319\n",
       "21    14695\n",
       "22    41534\n",
       "23    43082\n",
       "24    31445\n",
       "25     3798\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#check the negativly of values in database\n",
    "fd=pd.DataFrame(training_data)# triaing_data must be DataFrame\n",
    "(fd <0).sum(axis=0)# or \n",
    "fd.apply(lambda x: (x<0).sum(),axis=0)\n",
    "\n",
    "# all has zero so we will not use chi\n",
    "\n",
    "# #import the necessary libraries first\n",
    "# from sklearn.feature_selection import SelectKbest\n",
    "# #Feature extraction where k is the best k feature in datafram\n",
    "# test=SelectKBest(score_func=chi2,k=4)\n",
    "# fit=test.fit(train_set,goal_train)\n",
    "\n",
    "# #summarize scores\n",
    "# np.set_printoption(precision=3)\n",
    "# print(fit.scores_)\n",
    "# features=fit.transform(train_set)\n",
    "# features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement Recursive Feature Elimination RFE \n",
    "which is a type of Wrapper feature seleciton methon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected Feature: [False False False False False False False False False False False False\n",
      " False False  True False  True False False False False  True  True False\n",
      " False False]\n",
      "Feature Ranking: [21 14 17 20 19 15  9 13 18 16  7 11  6 12  1 10  1  3 23  5  8  1  1  4\n",
      "  2 22]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import library\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression(random_state = 0)\n",
    "rfe=RFE(logistic,4)# Where 4 is the top features\n",
    "rfe.fit(train_set,goal_train);\n",
    "print('selected Feature: %s'%(rfe.fit(train_set,goal_train).support_));\n",
    "print(\"Feature Ranking: %s\"%(rfe.fit(train_set,goal_train).ranking_));\n",
    "logistic.fit(train_set,  goal_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the LR module\n",
    "##using Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6414</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1203</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  6414   426\n",
       "1  1203  1002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(goal_test, logistic.predict(test_set))\n",
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8199004975124378"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.score(test_set, goal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36177 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "...   ..\n",
       "36172  0\n",
       "36173  1\n",
       "36174  1\n",
       "36175  0\n",
       "36176  0\n",
       "\n",
       "[36177 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape,goal_train.shape\n",
    "df=pd.DataFrame(goal_train)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.013207</td>\n",
       "      <td>-0.013719</td>\n",
       "      <td>-0.129373</td>\n",
       "      <td>0.129357</td>\n",
       "      <td>0.129382</td>\n",
       "      <td>-0.129477</td>\n",
       "      <td>0.094760</td>\n",
       "      <td>-0.094691</td>\n",
       "      <td>0.148467</td>\n",
       "      <td>-0.148457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121203</td>\n",
       "      <td>-0.035853</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>-0.028984</td>\n",
       "      <td>0.012710</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>0.064669</td>\n",
       "      <td>0.045882</td>\n",
       "      <td>0.038713</td>\n",
       "      <td>-0.005357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>-0.000892</td>\n",
       "      <td>-0.000892</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>-0.007942</td>\n",
       "      <td>0.007942</td>\n",
       "      <td>-0.001010</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121203</td>\n",
       "      <td>-0.035853</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>-0.028984</td>\n",
       "      <td>0.012710</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>0.064669</td>\n",
       "      <td>0.045882</td>\n",
       "      <td>0.038713</td>\n",
       "      <td>-0.005357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>-0.000905</td>\n",
       "      <td>-0.000905</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>-0.007953</td>\n",
       "      <td>0.007953</td>\n",
       "      <td>-0.001025</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121203</td>\n",
       "      <td>-0.035853</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>-0.028984</td>\n",
       "      <td>0.012710</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>0.064669</td>\n",
       "      <td>0.045882</td>\n",
       "      <td>0.038713</td>\n",
       "      <td>-0.005357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>-0.000905</td>\n",
       "      <td>-0.000905</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>-0.007952</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>-0.001025</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121189</td>\n",
       "      <td>-0.035852</td>\n",
       "      <td>0.004343</td>\n",
       "      <td>-0.028988</td>\n",
       "      <td>0.012709</td>\n",
       "      <td>0.050221</td>\n",
       "      <td>0.064665</td>\n",
       "      <td>0.045879</td>\n",
       "      <td>0.038712</td>\n",
       "      <td>-0.005356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>-0.000897</td>\n",
       "      <td>-0.000897</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>-0.007949</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>-0.001024</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121063</td>\n",
       "      <td>-0.035842</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>-0.029022</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>0.050165</td>\n",
       "      <td>0.064623</td>\n",
       "      <td>0.045849</td>\n",
       "      <td>0.038705</td>\n",
       "      <td>-0.005343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.000824</td>\n",
       "      <td>-0.000824</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.007913</td>\n",
       "      <td>0.007913</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119822</td>\n",
       "      <td>-0.035747</td>\n",
       "      <td>0.004460</td>\n",
       "      <td>-0.029353</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>0.049618</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>0.045553</td>\n",
       "      <td>0.038631</td>\n",
       "      <td>-0.005219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>-0.000890</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>-0.005378</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060370</td>\n",
       "      <td>-0.025771</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>-0.029573</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>0.028617</td>\n",
       "      <td>0.037368</td>\n",
       "      <td>0.026394</td>\n",
       "      <td>0.028895</td>\n",
       "      <td>-0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.003716</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>-0.003716</td>\n",
       "      <td>-0.002660</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>-0.000551</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>-0.011523</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>-0.014467</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>0.013246</td>\n",
       "      <td>0.000775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>-0.000324</td>\n",
       "      <td>-0.002875</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>-0.002875</td>\n",
       "      <td>-0.001707</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012361</td>\n",
       "      <td>-0.006826</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>-0.008717</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>-0.001879</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>-0.001879</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>-0.003767</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>-0.004856</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004324</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.013207 -0.013719 -0.129373  0.129357  0.129382 -0.129477  0.094760   \n",
       "1  0.000718 -0.000720  0.000892 -0.000892 -0.000892  0.000892 -0.007942   \n",
       "2  0.000718 -0.000718  0.000905 -0.000905 -0.000905  0.000905 -0.007953   \n",
       "3  0.000718 -0.000718  0.000905 -0.000905 -0.000905  0.000905 -0.007952   \n",
       "4  0.000718 -0.000718  0.000897 -0.000897 -0.000897  0.000897 -0.007949   \n",
       "5  0.000724 -0.000724  0.000824 -0.000824 -0.000824  0.000824 -0.007913   \n",
       "6  0.000890 -0.000890 -0.002876  0.002876  0.002876 -0.002876 -0.005378   \n",
       "7  0.000529 -0.000529 -0.003716  0.003716  0.003716 -0.003716 -0.002660   \n",
       "8  0.000324 -0.000324 -0.002875  0.002875  0.002875 -0.002875 -0.001707   \n",
       "9  0.000179 -0.000179 -0.001879  0.001879  0.001879 -0.001879 -0.001007   \n",
       "\n",
       "         7         8         9   ...        16        17        18        19  \\\n",
       "0 -0.094691  0.148467 -0.148457  ...  0.121203 -0.035853  0.004341 -0.028984   \n",
       "1  0.007942 -0.001010  0.001010  ...  0.121203 -0.035853  0.004341 -0.028984   \n",
       "2  0.007953 -0.001025  0.001025  ...  0.121203 -0.035853  0.004341 -0.028984   \n",
       "3  0.007952 -0.001025  0.001025  ...  0.121189 -0.035852  0.004343 -0.028988   \n",
       "4  0.007949 -0.001024  0.001024  ...  0.121063 -0.035842  0.004354 -0.029022   \n",
       "5  0.007913 -0.001013  0.001013  ...  0.119822 -0.035747  0.004460 -0.029353   \n",
       "6  0.005378 -0.000491  0.000491  ...  0.060370 -0.025771  0.005925 -0.029573   \n",
       "7  0.002660 -0.000551  0.000551  ...  0.021876 -0.011523  0.002875 -0.014467   \n",
       "8  0.001707 -0.000514  0.000514  ...  0.012361 -0.006826  0.001704 -0.008717   \n",
       "9  0.001007 -0.000381  0.000381  ...  0.006640 -0.003767  0.000938 -0.004856   \n",
       "\n",
       "         20        21        22        23        24        25  \n",
       "0  0.012710  0.050228  0.064669  0.045882  0.038713 -0.005357  \n",
       "1  0.012710  0.050228  0.064669  0.045882  0.038713 -0.005357  \n",
       "2  0.012710  0.050228  0.064669  0.045882  0.038713 -0.005357  \n",
       "3  0.012709  0.050221  0.064665  0.045879  0.038712 -0.005356  \n",
       "4  0.012703  0.050165  0.064623  0.045849  0.038705 -0.005343  \n",
       "5  0.012641  0.049618  0.064213  0.045553  0.038631 -0.005219  \n",
       "6  0.008876  0.028617  0.037368  0.026394  0.028895 -0.000189  \n",
       "7  0.004149  0.012641  0.014165  0.009969  0.013246  0.000775  \n",
       "8  0.002485  0.007524  0.008041  0.005651  0.007895  0.000572  \n",
       "9  0.001378  0.004167  0.004324  0.003036  0.004373  0.000353  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Ridge technique to get the coefficient R squar\n",
    "coeff_matrix = []\n",
    "\n",
    "for alpha in [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]:\n",
    "    from sklearn.linear_model import Ridge\n",
    "    ridge = Ridge(alpha = alpha, copy_X=True, fit_intercept=True , max_iter=None, \\\n",
    "              normalize=True,random_state=None,solver=\"auto\" ,tol=0.001)\n",
    "#     ridge.fit(poly_features, salarys)\n",
    "    ridge.fit(train_set,goal_train)\n",
    "    coeff_matrix.append(ridge.coef_)\n",
    "\n",
    "pd.DataFrame(coeff_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00018 * X0+-0.00018 * X1+-0.00188 * X2+0.00188 * X3+0.00188 * X4+-0.00188 * X5+-0.00101 * X6+0.00101 * X7+-0.00038 * X8+0.00038 * X9+-0.0025 * X10+0.0025 * X11+0.00027 * X12+7e-05 * X13+0.00454 * X14+0.00151 * X15+0.00664 * X16+-0.00377 * X17+0.00094 * X18+-0.00486 * X19+0.00138 * X20+0.00417 * X21+0.00432 * X22+0.00304 * X23+0.00437 * X24+0.00035 * X25\n"
     ]
    }
   ],
   "source": [
    "# A helper method for pretty-printing the coefficients\n",
    "def pretty_print_coefs(coefs, names=None , sort=False):\n",
    "    if names==None:\n",
    "        names=[\"X%s\"%x for x in range(len(coefs))]\n",
    "    st=zip(coefs,names)\n",
    "    if sort:\n",
    "        st=sorted(st,key=lambda x : -np.abs(x[0]))\n",
    "    return \"+\".join(\"%s * %s\"% (round(coefs,5),name)for coefs ,name in st)\n",
    "print(pretty_print_coefs(ridge.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T21:42:40.423673Z",
     "start_time": "2020-02-06T21:42:40.419125Z"
    }
   },
   "outputs": [],
   "source": [
    "# # define a function that return whatever degree polynomial you want\n",
    "# def getPolynomial(data,degree=1):\n",
    "#     if degree == 1 :\n",
    "#         return data \n",
    "#     from sklearn.preprocessing import PolynomialFeatures\n",
    "#     poly = PolynomialFeatures(degree= degree)\n",
    "#     poly_features = poly.fit_transform(data)\n",
    "#     return poly_features\n",
    "# define a function for plotting\n",
    "def plot(feature = [], actual = [], predicted = [], alpha = 1):\n",
    "    plt.plot(feature, actual, '-')\n",
    "#     plt.legend(handles=\"actual\")\n",
    "    plt.plot( feature, predicted, '*')\n",
    "#     plt.legend(handles=\"predicted\")\n",
    "    plt.title('alpha = {}'.format(alpha))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T21:42:41.288913Z",
     "start_time": "2020-02-06T21:42:40.425445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046403</td>\n",
       "      <td>-0.390005</td>\n",
       "      <td>1.746102</td>\n",
       "      <td>-0.884479</td>\n",
       "      <td>0.38411</td>\n",
       "      <td>0.693813</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-0.390005</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>2.245982</td>\n",
       "      <td>0.38411</td>\n",
       "      <td>-1.441310</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345316</td>\n",
       "      <td>0.942936</td>\n",
       "      <td>0.255921</td>\n",
       "      <td>0.993798</td>\n",
       "      <td>0.38411</td>\n",
       "      <td>-1.441310</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>-0.411249</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>1.671940</td>\n",
       "      <td>1.671940</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>-3.686155</td>\n",
       "      <td>3.686155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.520471</td>\n",
       "      <td>-0.390005</td>\n",
       "      <td>0.752648</td>\n",
       "      <td>-0.884479</td>\n",
       "      <td>0.38411</td>\n",
       "      <td>0.693813</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>4.663284</td>\n",
       "      <td>0.338291</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046403</td>\n",
       "      <td>-0.390005</td>\n",
       "      <td>1.746102</td>\n",
       "      <td>-0.884479</td>\n",
       "      <td>0.38411</td>\n",
       "      <td>0.693813</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36172</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046403</td>\n",
       "      <td>0.942936</td>\n",
       "      <td>0.752648</td>\n",
       "      <td>-0.258387</td>\n",
       "      <td>0.38411</td>\n",
       "      <td>-1.441310</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36173</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>1.671940</td>\n",
       "      <td>1.671940</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345316</td>\n",
       "      <td>-0.390005</td>\n",
       "      <td>-0.737534</td>\n",
       "      <td>-0.884479</td>\n",
       "      <td>0.38411</td>\n",
       "      <td>0.693813</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>1.587523</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36174</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>1.671940</td>\n",
       "      <td>1.671940</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128753</td>\n",
       "      <td>-0.390005</td>\n",
       "      <td>-0.737534</td>\n",
       "      <td>-0.884479</td>\n",
       "      <td>0.38411</td>\n",
       "      <td>0.693813</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>1.171112</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36175</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-0.390005</td>\n",
       "      <td>-0.737534</td>\n",
       "      <td>-0.884479</td>\n",
       "      <td>0.38411</td>\n",
       "      <td>0.693813</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36176</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.021554</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>-0.598108</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>0.271285</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-1.722946</td>\n",
       "      <td>-0.985897</td>\n",
       "      <td>-0.258387</td>\n",
       "      <td>0.38411</td>\n",
       "      <td>0.693813</td>\n",
       "      <td>0.296225</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>-0.494531</td>\n",
       "      <td>0.262999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36177 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.021554 -0.021554  0.598108 -0.598108 -0.598108  0.598108  0.179133   \n",
       "1      0.021554 -0.021554  0.598108 -0.598108 -0.598108  0.598108  0.179133   \n",
       "2      0.021554 -0.021554  0.598108 -0.598108 -0.598108  0.598108  0.179133   \n",
       "3      0.021554 -0.021554 -1.671940  1.671940  1.671940 -1.671940  0.179133   \n",
       "4      0.021554 -0.021554  0.598108 -0.598108 -0.598108  0.598108  0.179133   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36172  0.021554 -0.021554  0.598108 -0.598108 -0.598108  0.598108  0.179133   \n",
       "36173  0.021554 -0.021554 -1.671940  1.671940  1.671940 -1.671940  0.179133   \n",
       "36174  0.021554 -0.021554 -1.671940  1.671940  1.671940 -1.671940  0.179133   \n",
       "36175  0.021554 -0.021554  0.598108 -0.598108 -0.598108  0.598108  0.179133   \n",
       "36176  0.021554 -0.021554  0.598108 -0.598108 -0.598108  0.598108  0.179133   \n",
       "\n",
       "             7         8         9   ...        16        17        18  \\\n",
       "0     -0.179133  0.271285 -0.271285  ... -0.046403 -0.390005  1.746102   \n",
       "1     -0.179133  0.271285 -0.271285  ... -0.438122 -0.390005  0.007557   \n",
       "2     -0.179133  0.271285 -0.271285  ...  0.345316  0.942936  0.255921   \n",
       "3     -0.179133 -3.686155  3.686155  ...  1.520471 -0.390005  0.752648   \n",
       "4     -0.179133  0.271285 -0.271285  ... -0.046403 -0.390005  1.746102   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "36172 -0.179133  0.271285 -0.271285  ... -0.046403  0.942936  0.752648   \n",
       "36173 -0.179133  0.271285 -0.271285  ...  0.345316 -0.390005 -0.737534   \n",
       "36174 -0.179133  0.271285 -0.271285  ...  1.128753 -0.390005 -0.737534   \n",
       "36175 -0.179133  0.271285 -0.271285  ... -0.438122 -0.390005 -0.737534   \n",
       "36176 -0.179133  0.271285 -0.271285  ... -0.438122 -1.722946 -0.985897   \n",
       "\n",
       "             19       20        21        22        23        24        25  \n",
       "0     -0.884479  0.38411  0.693813 -0.146733 -0.218780  0.754701  0.262999  \n",
       "1      2.245982  0.38411 -1.441310 -0.146733 -0.218780 -0.078120  0.262999  \n",
       "2      0.993798  0.38411 -1.441310 -0.146733 -0.218780 -0.411249  0.262999  \n",
       "3     -0.884479  0.38411  0.693813 -0.146733  4.663284  0.338291  0.262999  \n",
       "4     -0.884479  0.38411  0.693813 -0.146733 -0.218780  0.754701  0.262999  \n",
       "...         ...      ...       ...       ...       ...       ...       ...  \n",
       "36172 -0.258387  0.38411 -1.441310 -0.146733 -0.218780 -0.078120  0.262999  \n",
       "36173 -0.884479  0.38411  0.693813 -0.146733 -0.218780  1.587523  0.262999  \n",
       "36174 -0.884479  0.38411  0.693813 -0.146733 -0.218780  1.171112  0.262999  \n",
       "36175 -0.884479  0.38411  0.693813 -0.146733 -0.218780 -0.078120  0.262999  \n",
       "36176 -0.258387  0.38411  0.693813  0.296225 -0.218780 -0.494531  0.262999  \n",
       "\n",
       "[36177 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# poly_features = getPolynomial(features, 13)\n",
    "pd.DataFrame(train_set)# replace poly_features as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using KNN and with multiple K's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 11.000000\n",
      "-------------\n",
      "      0     1\n",
      "0  6209   631\n",
      "1   887  1318\n",
      "\n",
      "model accuracy : 0.8322\n",
      "-------------\n",
      "\n",
      "\n",
      "K = 12.000000\n",
      "-------------\n",
      "      0     1\n",
      "0  6324   516\n",
      "1   978  1227\n",
      "\n",
      "model accuracy : 0.8348\n",
      "-------------\n",
      "\n",
      "\n",
      "K = 13.000000\n",
      "-------------\n",
      "      0     1\n",
      "0  6228   612\n",
      "1   890  1315\n",
      "\n",
      "model accuracy : 0.8339\n",
      "-------------\n",
      "\n",
      "\n",
      "{'k_11': '0.832172', 'k_12': '0.834826', 'k_13': '0.833941'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier.fit(train_set, goal_train)\n",
    "accuracy={}\n",
    "for K in [  11,12,13]:\n",
    "    classifier = KNeighborsClassifier(n_neighbors=K)\n",
    "    classifier.fit(train_set, goal_train)\n",
    "    cm = confusion_matrix(goal_test, classifier.predict(test_set))\n",
    "    accuracy[\"k_%d\"%K]=\"%4f\"%classifier.score(test_set,goal_test)\n",
    "#     accuracy.__setitem__(k,classifier.score(test_set,goal_test))\n",
    "    \n",
    "    print('K = %4f\\n-------------'%K)\n",
    "\n",
    "    print(pd.DataFrame(cm))\n",
    "\n",
    "    print(\"\\nmodel accuracy : {:.4f}\".format(classifier.score(test_set, goal_test)))\n",
    "\n",
    "    print('-------------\\n\\n')\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(accuracy)),accuracy.values(),align=\"center\")\n",
    "plt.xticks(range(len(accuracy)),list(accuracy.keys()))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From above we get that the KNN model(for k=12 accuracy=0.8347) is mor accurate than logistic regression(accuracy=0.534)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(train_set, goal_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7751243781094528\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5944</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1138</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  5944   896\n",
       "1  1138  1067"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(goal_test, classifier.predict(test_set))\n",
    "print(classifier.score(test_set, goal_test))\n",
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the training data--need to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (23444964,2) (26,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5546ab3443d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m X1, X2= np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n\u001b[1;32m      5\u001b[0m                      np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontourf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/1A746F7B746F5891/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/1A746F7B746F5891/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mjointi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_prior_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mn_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) /\n\u001b[0m\u001b[1;32m    436\u001b[0m                                  (self.sigma_[i, :]), 1)\n\u001b[1;32m    437\u001b[0m             \u001b[0mjoint_log_likelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjointi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (23444964,2) (26,) "
     ]
    }
   ],
   "source": [
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = train_set, goal_train\n",
    "X1, X2= np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], label = j)\n",
    "plt.title('naive bayes Classification (Training set)')\n",
    "plt.xlabel('taining')\n",
    "plt.ylabel('price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clf(classifier, clf_name, step_size=0.01):\n",
    "    classifier.fit(train_set, goal_train)\n",
    "    cm = confusion_matrix(goal_test, classifier.predict(test_set))\n",
    "    print(classifier.score(test_set, goal_test))\n",
    "#     X_set, y_set = train_set, goal_train\n",
    "#     X1, X2= np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = step_size),\n",
    "#                          np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = step_size))\n",
    "#     plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape))\n",
    "#     plt.xlim(X1.min(), X1.max())\n",
    "#     plt.ylim(X2.min(), X2.max())\n",
    "#     for i, j in enumerate(np.unique(y_set)):\n",
    "#         plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], label = j)\n",
    "#     plt.title('{} Classification (Training set)'.format(clf_name))\n",
    "#     plt.xlabel('Age')\n",
    "#     plt.ylabel('Estimated Salary')\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BernoulliNB()\n",
    "test_clf(clf, \"BernoulliNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(train_set, goal_train)\n",
    "clf.score(test_set, goal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#train_set, test_set, goal_train, goal_test\n",
    "# classifiers\n",
    "l_svm = LinearSVC(random_state=0)\n",
    "svc = SVC(random_state=0)\n",
    "lr = LogisticRegression(random_state=0)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# training\n",
    "l_svm.fit(train_set, goal_train)\n",
    "svc.fit(train_set, goal_train)\n",
    "lr.fit(train_set, goal_train)\n",
    "knn.fit(train_set, goal_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = l_svm.predict(test_set)\n",
    "\n",
    "print(precision_score(goal_test, y_pred, average='micro'))\n",
    "print(recall_score(goal_test, y_pred, average='micro'))\n",
    "print(f1_score(goal_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(goal_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, label in zip([l_svm, svc, knn, lr], ['LinearSVC', 'SVC', 'KNeighborsClassifier', 'LogisticRegression']):\n",
    "    print(\"{} report:\".format(label))\n",
    "    y_pred = clf.predict(test_set)\n",
    "    print(classification_report(goal_test, y_pred))\n",
    "    print(\"\\n---------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying KNN on  Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying KNN on  Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = knn, X = train_set, y = goal_train, cv = 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean of Accuracy and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean of acc:\", accuracies.mean())\n",
    "print(\"Standard diviation of acc:\", accuracies.std())\n",
    "print(\"model acc : {:.2f} (+/- {:.2f})%\".format(accuracies.mean(), accuracies.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = [{\"penalty\": [\"l1\", \"l2\", \"elasticnet\"], \n",
    "               \"loss\":[\"hinge\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\"]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(train_set, goal_train)\n",
    "print(\"best accuracy is :\" , grid_search.best_score_)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=KNeighborsClassifier(n_neighbors=K)\n",
    "parameters=[{\"n_neighbors\":[11,12,13],\"leaf_size\":[1,3,5],\n",
    "            \"algorithm\":[\"auto\",\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "            \"n_jobs\":[-1]}]\n",
    "\n",
    "grid_search=GridSearchCV(estimator=classifier,\n",
    "                        param_grid=parameters,\n",
    "                        cv=10)\n",
    "grid_search = grid_search.fit(train_set, goal_train)\n",
    "print(\"best accuracy is :\" , grid_search.best_score_)\n",
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
